{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'F:\\GIT_Projects\\Regression model\\bike_share\\ML_Regression_Model\\day.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of the Bike Sharing Demand dataset:\n",
      "   instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
      "0        1  2011-01-01       1   0     1        0        6           0   \n",
      "1        2  2011-01-02       1   0     1        0        0           0   \n",
      "2        3  2011-01-03       1   0     1        0        1           1   \n",
      "3        4  2011-01-04       1   0     1        0        2           1   \n",
      "4        5  2011-01-05       1   0     1        0        3           1   \n",
      "\n",
      "   weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
      "0           2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
      "1           2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
      "2           1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
      "3           1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
      "4           1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
      "\n",
      "    cnt  \n",
      "0   985  \n",
      "1   801  \n",
      "2  1349  \n",
      "3  1562  \n",
      "4  1600  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the dataset\n",
    "print(\"Sample of the Bike Sharing Demand dataset:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = data.drop(['cnt', 'casual', 'registered', 'dteday'], axis=1)  # Assuming 'count' as the target\n",
    "y = data['cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identify numeric and categorical features\n",
    "numeric_features = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "categorical_features = ['season', 'holiday', 'workingday', 'weathersit', 'yr', 'mnth', 'weekday']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for numeric features: impute missing values and scale\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical features: impute missing values and one-hot encode\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline with DecisionTreeRegressor\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 867814.1836734693\n",
      "R-squared (R2) Score: 0.7835811325074993\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R-squared (R2) Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "\n",
      "Best Parameters from RandomizedSearchCV: {'regressor__min_samples_split': 10, 'regressor__min_samples_leaf': 6, 'regressor__max_depth': 10}\n",
      "Best CV Score from RandomizedSearchCV: 0.7897952562400541\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'regressor__max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'regressor__min_samples_split': [2, 5, 10, 15, 20],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4, 6, 8]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, n_iter=50, cv=5, verbose=1, n_jobs=-1, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Parameters from RandomizedSearchCV:\", random_search.best_params_)\n",
    "print(\"Best CV Score from RandomizedSearchCV:\", random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "\n",
      "Best Parameters from GridSearchCV: {'regressor__max_depth': 10, 'regressor__min_samples_leaf': 6, 'regressor__min_samples_split': 8}\n",
      "Best CV Score from GridSearchCV: 0.7897952562400541\n",
      "\n",
      "Mean Squared Error (MSE) - Tuned Model: 808603.8474187402\n",
      "R-squared (R2) Score - Tuned Model: 0.7983472358475666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:542: FitFailedWarning: \n",
      "45 fits failed out of a total of 135.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hp\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hp\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py\", line 1351, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hp\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\hp\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py\", line 1344, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\hp\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\hp\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of DecisionTreeRegressor must be an int in the range [1, inf) or None. Got 0 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.7809839  0.7809839  0.78521866\n",
      " 0.78979526 0.78979526 0.78979526 0.78720926 0.78720926 0.78720926\n",
      " 0.77728016 0.77728016 0.78834675 0.78863582 0.78863582 0.78863582\n",
      " 0.789795   0.789795   0.789795  ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Using the best parameters from RandomizedSearchCV to narrow down the GridSearchCV\n",
    "param_grid = {\n",
    "    'regressor__max_depth': [random_search.best_params_['regressor__max_depth'] - 10, random_search.best_params_['regressor__max_depth'], random_search.best_params_['regressor__max_depth'] + 10],\n",
    "    'regressor__min_samples_split': [random_search.best_params_['regressor__min_samples_split'] - 2, random_search.best_params_['regressor__min_samples_split'], random_search.best_params_['regressor__min_samples_split'] + 2],\n",
    "    'regressor__min_samples_leaf': [random_search.best_params_['regressor__min_samples_leaf'] - 1, random_search.best_params_['regressor__min_samples_leaf'], random_search.best_params_['regressor__min_samples_leaf'] + 1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Parameters from GridSearchCV:\", grid_search.best_params_)\n",
    "print(\"Best CV Score from GridSearchCV:\", grid_search.best_score_)\n",
    "\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "y_pred_tuned = best_pipeline.predict(X_test)\n",
    "\n",
    "mse_tuned = mean_squared_error(y_test, y_pred_tuned)\n",
    "r2_tuned = r2_score(y_test, y_pred_tuned)\n",
    "\n",
    "print(\"\\nMean Squared Error (MSE) - Tuned Model:\", mse_tuned)\n",
    "print(\"R-squared (R2) Score - Tuned Model:\", r2_tuned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bike_sharing_demand_model.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "joblib.dump(best_pipeline, 'bike_sharing_demand_model.pkl')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
